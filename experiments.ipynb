{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\preet\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\preet\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import utils, optim, device, inference_mode\n",
    "import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import ConfusionMatrix\n",
    "import mlxtend\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import numpy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'pathmnist'\n",
    "# data_flag = 'dermamnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: multi-class\n",
      "channels:  3\n",
      "classes: 9\n"
     ]
    }
   ],
   "source": [
    "print('task:', task)\n",
    "print('channels: ', n_channels)\n",
    "print('classes:', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: pathmnist_data\\pathmnist_224.npz\n",
      "Using downloaded and verified file: pathmnist_data\\pathmnist_224.npz\n",
      "Using downloaded and verified file: pathmnist_data\\pathmnist_224.npz\n"
     ]
    }
   ],
   "source": [
    "train_data = DataClass(root='pathmnist_data', split='train', transform=data_transform, size=224, mmap_mode='r' ,download=True)\n",
    "val_data = DataClass(root='pathmnist_data', split='val', transform=data_transform, size=224, mmap_mode='r', download=True)\n",
    "test_data = DataClass(root='pathmnist_data', split='test', transform=data_transform, size=224, mmap_mode='r', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "train_sample = train_data[0]\n",
    "print(train_sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random data loaders for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data into dataloader form\n",
    "BATCH_SIZE = 256\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResnetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\preet\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\preet\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\preet/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 27.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TeacherResnet50(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TeacherResnet50, self).__init__()\n",
    "#         self.teacher_resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "#         self.layers = list(self.teacher_resnet50.children())[:-1]\n",
    "        \n",
    "#         for param in self.teacher_resnet50.parameters():\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         print(self.layers)\n",
    "#         for layer in self.layers:\n",
    "#             x = layer(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherResnet50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherResnet50, self).__init__()\n",
    "        self.resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.resnet50.fc = torch.nn.Identity()  # Remove the last layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\preet\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\preet\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "# test the teacher model with a sample tensor\n",
    "test_tensor = torch.randn(1, 3, 224, 224)\n",
    "teacher_model = TeacherResnet50()\n",
    "output = teacher_model(test_tensor)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
    "mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentMobileNetV3(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(StudentMobileNetV3, self).__init__()\n",
    "        self.mobilenet_v3 = torchvision.models.mobilenet_v3_small(pretrained=False)\n",
    "        self.mobilenet_v3.classifier[3] = torch.nn.Identity()  # Remove the last layer\n",
    "        self.linear = torch.nn.Linear(1024, 2048)\n",
    "        self.fc = torch.nn.Linear(1024, num_classes)  # Add a new fully connected layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mobilenet_v3(x)\n",
    "        return self.linear(x), self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\preet\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# test the student model with a sample tensor\n",
    "student_model = StudentMobileNetV3(num_classes=n_classes)\n",
    "embedding, output = student_model(test_tensor)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training With Cosine Loss and Student Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiple_outputs(student_model, test_loader, device, validation = False):\n",
    "    student_model.to(device)\n",
    "    student_model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            labels = labels.squeeze(1)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            _, outputs = student_model(inputs) # Disregard the first tensor of the tuple\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # print(\"predicted.shape =\", predicted.shape)\n",
    "            # print(\"label.shape =\", labels.shape)\n",
    "            \n",
    "            # print(\"total number of samples in this batch:\", labels.size(0))\n",
    "            # print(\"correctly classified samples in this batch:\", (predicted == labels).sum().item())\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # print(\"correct = \", correct)\n",
    "    # print(\"total = \", total)\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    if validation:\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cosine_loss(teacher, student, train_loader, val_loader, epochs, learning_rate, hidden_rep_loss_weight, ce_loss_weight, device):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    cosine_loss = nn.CosineEmbeddingLoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
    "    \n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval()  # Teacher set to evaluation mode\n",
    "    student.train() # Student to train mode\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with the teacher model and keep only the hidden representation\n",
    "            with torch.no_grad():\n",
    "                teacher_hidden_representation = teacher(inputs)\n",
    "                \n",
    "            # Forward pass with the student model\n",
    "            student_hidden_representation, student_logits = student(inputs)\n",
    "\n",
    "            # Calculate the cosine loss. Target is a vector of ones. From the loss formula above we can see that is the case where loss minimization leads to cosine similarity increase.\n",
    "            hidden_rep_loss = cosine_loss(student_hidden_representation, teacher_hidden_representation, target=torch.ones(inputs.size(0)).to(device))\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            # print(\"student logits shape:\", student_logits.shape)\n",
    "            # print(\"labels shape:\", labels.shape)\n",
    "            labels = labels.squeeze(1)\n",
    "            # print(\"labels shape:\", labels.shape)\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "        \n",
    "        # perform validation\n",
    "        accuracy = test_multiple_outputs(student, val_loader, device, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.3937030675905672\n",
      "Validation Accuracy: 8.92%\n",
      "Epoch 2/100, Loss: 0.4327007128687745\n",
      "Validation Accuracy: 92.56%\n",
      "Epoch 3/100, Loss: 0.17708203645253723\n",
      "Validation Accuracy: 95.56%\n",
      "Epoch 4/100, Loss: 0.13737372774630785\n",
      "Validation Accuracy: 95.89%\n",
      "Epoch 5/100, Loss: 0.11192736558785493\n",
      "Validation Accuracy: 96.21%\n",
      "Epoch 6/100, Loss: 0.10288054970177737\n",
      "Validation Accuracy: 96.58%\n",
      "Epoch 7/100, Loss: 0.09220552170352841\n",
      "Validation Accuracy: 96.94%\n",
      "Epoch 8/100, Loss: 0.08249164290133525\n",
      "Validation Accuracy: 97.55%\n",
      "Epoch 9/100, Loss: 0.08175810299475085\n",
      "Validation Accuracy: 97.45%\n",
      "Epoch 10/100, Loss: 0.07326256921938197\n",
      "Validation Accuracy: 98.12%\n",
      "Epoch 11/100, Loss: 0.07345142145641148\n",
      "Validation Accuracy: 96.51%\n",
      "Epoch 12/100, Loss: 0.07380022267303006\n",
      "Validation Accuracy: 97.94%\n",
      "Epoch 13/100, Loss: 0.0667750159574842\n",
      "Validation Accuracy: 97.99%\n",
      "Epoch 14/100, Loss: 0.06378577736904845\n",
      "Validation Accuracy: 98.61%\n",
      "Epoch 15/100, Loss: 0.06278720675882968\n",
      "Validation Accuracy: 98.01%\n",
      "Epoch 16/100, Loss: 0.05465111419008198\n",
      "Validation Accuracy: 98.32%\n",
      "Epoch 17/100, Loss: 0.05305714128983461\n",
      "Validation Accuracy: 98.02%\n",
      "Epoch 18/100, Loss: 0.053563839094501665\n",
      "Validation Accuracy: 98.22%\n",
      "Epoch 19/100, Loss: 0.04994760153137825\n",
      "Validation Accuracy: 97.99%\n",
      "Epoch 20/100, Loss: 0.053466551053464755\n",
      "Validation Accuracy: 98.60%\n",
      "Epoch 21/100, Loss: 0.05249139985641126\n",
      "Validation Accuracy: 98.21%\n",
      "Epoch 22/100, Loss: 0.045714525553524836\n",
      "Validation Accuracy: 98.35%\n",
      "Epoch 23/100, Loss: 0.05105717724125663\n",
      "Validation Accuracy: 98.54%\n",
      "Epoch 24/100, Loss: 0.04539104832590304\n",
      "Validation Accuracy: 98.78%\n",
      "Epoch 25/100, Loss: 0.046123169452502305\n",
      "Validation Accuracy: 98.06%\n",
      "Epoch 26/100, Loss: 0.04744424061341719\n",
      "Validation Accuracy: 98.86%\n",
      "Epoch 27/100, Loss: 0.04109831956024705\n",
      "Validation Accuracy: 97.59%\n",
      "Epoch 28/100, Loss: 0.04485045064939186\n",
      "Validation Accuracy: 98.44%\n",
      "Epoch 29/100, Loss: 0.041779841762036085\n",
      "Validation Accuracy: 98.51%\n",
      "Epoch 30/100, Loss: 0.03767776973439719\n",
      "Validation Accuracy: 98.33%\n",
      "Epoch 31/100, Loss: 0.038165305926337496\n",
      "Validation Accuracy: 98.77%\n",
      "Epoch 32/100, Loss: 0.04222991678927263\n",
      "Validation Accuracy: 98.99%\n",
      "Epoch 33/100, Loss: 0.03549270813395693\n",
      "Validation Accuracy: 98.07%\n",
      "Epoch 34/100, Loss: 0.042615970041052526\n",
      "Validation Accuracy: 98.17%\n",
      "Epoch 35/100, Loss: 0.039415981662883\n",
      "Validation Accuracy: 99.02%\n",
      "Epoch 36/100, Loss: 0.03980055180992084\n",
      "Validation Accuracy: 98.72%\n",
      "Epoch 37/100, Loss: 0.036696213588584214\n",
      "Validation Accuracy: 99.15%\n",
      "Epoch 38/100, Loss: 0.03545289966066114\n",
      "Validation Accuracy: 98.54%\n",
      "Epoch 39/100, Loss: 0.039893403390041465\n",
      "Validation Accuracy: 99.13%\n",
      "Epoch 40/100, Loss: 0.043220616707747635\n",
      "Validation Accuracy: 98.66%\n",
      "Epoch 41/100, Loss: 0.03271053650479933\n",
      "Validation Accuracy: 98.66%\n",
      "Epoch 42/100, Loss: 0.0358808190212585\n",
      "Validation Accuracy: 98.26%\n",
      "Epoch 43/100, Loss: 0.03271016947903924\n",
      "Validation Accuracy: 98.85%\n",
      "Epoch 44/100, Loss: 0.04160296299960464\n",
      "Validation Accuracy: 99.14%\n",
      "Epoch 45/100, Loss: 0.03373168986184861\n",
      "Validation Accuracy: 98.73%\n",
      "Epoch 46/100, Loss: 0.02910012975123457\n",
      "Validation Accuracy: 98.91%\n",
      "Epoch 47/100, Loss: 0.03384672736600888\n",
      "Validation Accuracy: 98.78%\n",
      "Epoch 48/100, Loss: 0.031371277317785745\n",
      "Validation Accuracy: 97.61%\n",
      "Epoch 49/100, Loss: 0.031689149062995886\n",
      "Validation Accuracy: 98.82%\n",
      "Epoch 50/100, Loss: 0.03296001431193541\n",
      "Validation Accuracy: 99.05%\n",
      "Epoch 51/100, Loss: 0.03629969611806287\n",
      "Validation Accuracy: 98.25%\n",
      "Epoch 52/100, Loss: 0.03206170062979006\n",
      "Validation Accuracy: 99.15%\n",
      "Epoch 53/100, Loss: 0.03566562085920437\n",
      "Validation Accuracy: 99.10%\n",
      "Epoch 54/100, Loss: 0.0309750605692071\n",
      "Validation Accuracy: 98.82%\n",
      "Epoch 55/100, Loss: 0.031468548012939704\n",
      "Validation Accuracy: 98.87%\n",
      "Epoch 56/100, Loss: 0.029710296895989977\n",
      "Validation Accuracy: 98.92%\n",
      "Epoch 57/100, Loss: 0.03282821302259849\n",
      "Validation Accuracy: 98.89%\n",
      "Epoch 58/100, Loss: 0.030995141799477013\n",
      "Validation Accuracy: 98.96%\n",
      "Epoch 59/100, Loss: 0.030011028644036163\n",
      "Validation Accuracy: 99.17%\n",
      "Epoch 60/100, Loss: 0.029155925334304233\n",
      "Validation Accuracy: 99.10%\n",
      "Epoch 61/100, Loss: 0.025603901499628344\n",
      "Validation Accuracy: 99.30%\n",
      "Epoch 62/100, Loss: 0.03516929154813459\n",
      "Validation Accuracy: 98.80%\n",
      "Epoch 63/100, Loss: 0.028735160970510067\n",
      "Validation Accuracy: 98.90%\n",
      "Epoch 64/100, Loss: 0.029004413877952506\n",
      "Validation Accuracy: 98.90%\n",
      "Epoch 65/100, Loss: 0.031912651383953\n",
      "Validation Accuracy: 98.94%\n",
      "Epoch 66/100, Loss: 0.03168192215856503\n",
      "Validation Accuracy: 98.84%\n",
      "Epoch 67/100, Loss: 0.03012563457014039\n",
      "Validation Accuracy: 98.84%\n",
      "Epoch 68/100, Loss: 0.02658614312002266\n",
      "Validation Accuracy: 98.85%\n",
      "Epoch 69/100, Loss: 0.02990070738914338\n",
      "Validation Accuracy: 99.03%\n",
      "Epoch 70/100, Loss: 0.025901801450262694\n",
      "Validation Accuracy: 99.22%\n",
      "Epoch 71/100, Loss: 0.03096229243303903\n",
      "Validation Accuracy: 98.99%\n",
      "Epoch 72/100, Loss: 0.03173622510141947\n",
      "Validation Accuracy: 99.18%\n",
      "Epoch 73/100, Loss: 0.024989387454380365\n",
      "Validation Accuracy: 99.11%\n",
      "Epoch 74/100, Loss: 0.029897289276546377\n",
      "Validation Accuracy: 98.98%\n",
      "Epoch 75/100, Loss: 0.03142979413016953\n",
      "Validation Accuracy: 98.79%\n",
      "Epoch 76/100, Loss: 0.023631265926682812\n",
      "Validation Accuracy: 99.27%\n",
      "Epoch 77/100, Loss: 0.024939526227006518\n",
      "Validation Accuracy: 99.31%\n",
      "Epoch 78/100, Loss: 0.0307973682700487\n",
      "Validation Accuracy: 99.12%\n",
      "Epoch 79/100, Loss: 0.026672453577206892\n",
      "Validation Accuracy: 99.01%\n",
      "Epoch 80/100, Loss: 0.02779498425397006\n",
      "Validation Accuracy: 99.14%\n",
      "Epoch 81/100, Loss: 0.026127616435670378\n",
      "Validation Accuracy: 99.06%\n",
      "Epoch 82/100, Loss: 0.02509676261847331\n",
      "Validation Accuracy: 98.97%\n",
      "Epoch 83/100, Loss: 0.025076178817967462\n",
      "Validation Accuracy: 98.98%\n",
      "Epoch 84/100, Loss: 0.025423355231230908\n",
      "Validation Accuracy: 99.12%\n",
      "Epoch 85/100, Loss: 0.03028213136977601\n",
      "Validation Accuracy: 98.99%\n",
      "Epoch 86/100, Loss: 0.026406089526558804\n",
      "Validation Accuracy: 98.93%\n",
      "Epoch 87/100, Loss: 0.027457674012773416\n",
      "Validation Accuracy: 98.78%\n",
      "Epoch 88/100, Loss: 0.0258804838151925\n",
      "Validation Accuracy: 99.14%\n",
      "Epoch 89/100, Loss: 0.026186984423971313\n",
      "Validation Accuracy: 99.04%\n",
      "Epoch 90/100, Loss: 0.025413463029756465\n",
      "Validation Accuracy: 99.19%\n",
      "Epoch 91/100, Loss: 0.025437689703804525\n",
      "Validation Accuracy: 98.93%\n",
      "Epoch 92/100, Loss: 0.025515624205581844\n",
      "Validation Accuracy: 99.42%\n",
      "Epoch 93/100, Loss: 0.026009334198368542\n",
      "Validation Accuracy: 98.28%\n",
      "Epoch 94/100, Loss: 0.02637944465227933\n",
      "Validation Accuracy: 99.26%\n",
      "Epoch 95/100, Loss: 0.023601228672884066\n",
      "Validation Accuracy: 99.28%\n",
      "Epoch 96/100, Loss: 0.027788801658475262\n",
      "Validation Accuracy: 99.07%\n",
      "Epoch 97/100, Loss: 0.022946291492024266\n",
      "Validation Accuracy: 99.27%\n",
      "Epoch 98/100, Loss: 0.02140043640974909\n",
      "Validation Accuracy: 99.34%\n",
      "Epoch 99/100, Loss: 0.029535207971507174\n",
      "Validation Accuracy: 99.15%\n",
      "Epoch 100/100, Loss: 0.027840211696457118\n",
      "Validation Accuracy: 99.24%\n",
      "Test Accuracy: 91.92%\n"
     ]
    }
   ],
   "source": [
    "# Train and test the lightweight network with cross entropy loss\n",
    "train_cosine_loss(teacher=teacher_model, student=student_model, train_loader=train_dataloader, val_loader=val_dataloader, epochs=100, learning_rate=0.001, hidden_rep_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
    "test_accuracy_light_ce_and_cosine_loss = test_multiple_outputs(student_model, test_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
